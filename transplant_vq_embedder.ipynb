{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongmin/.local/share/virtualenvs/audiocraft-ssbSDm-j/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.1.0+cu121 with CUDA 1201 (you have 2.1.0+cu118)\n",
      "    Python  3.8.18 (you have 3.8.10)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    }
   ],
   "source": [
    "from audiocraft.models import CompressionModel, HFEncodecCompressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongmin/.local/share/virtualenvs/audiocraft-ssbSDm-j/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "model = CompressionModel.get_pretrained('facebook/encodec_32khz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HF to NonHF Converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = model.model.state_dict()\n",
    "new_state = {}\n",
    "for k, v in state.items():\n",
    "    if k.startswith('decoder.layers') and '.conv.' in k and '.block.' not in k:\n",
    "        # We need to determine if this a convtr or a regular conv.\n",
    "        layer = int(k.split('.')[2])\n",
    "        if isinstance(model.model.decoder.layers[layer].conv, torch.nn.ConvTranspose1d):\n",
    "\n",
    "            k = k.replace('.conv.', '.convtr.')\n",
    "    k = k.replace('encoder.layers.', 'encoder.model.')\n",
    "    k = k.replace('decoder.layers.', 'decoder.model.')\n",
    "    k = k.replace('conv.', 'conv.conv.')\n",
    "    k = k.replace('convtr.', 'convtr.convtr.')\n",
    "    k = k.replace('quantizer.layers.', 'quantizer.vq.layers.')\n",
    "    k = k.replace('.codebook.', '._codebook.')\n",
    "    new_state[k] = v\n",
    "state = new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state, \"encodec_32khz_whole_nonHF.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['quantizer.vq.layers.0._codebook.inited', 'quantizer.vq.layers.0._codebook.cluster_size', 'quantizer.vq.layers.0._codebook.embed', 'quantizer.vq.layers.0._codebook.embed_avg', 'quantizer.vq.layers.1._codebook.inited', 'quantizer.vq.layers.1._codebook.cluster_size', 'quantizer.vq.layers.1._codebook.embed', 'quantizer.vq.layers.1._codebook.embed_avg', 'quantizer.vq.layers.2._codebook.inited', 'quantizer.vq.layers.2._codebook.cluster_size', 'quantizer.vq.layers.2._codebook.embed', 'quantizer.vq.layers.2._codebook.embed_avg', 'quantizer.vq.layers.3._codebook.inited', 'quantizer.vq.layers.3._codebook.cluster_size', 'quantizer.vq.layers.3._codebook.embed', 'quantizer.vq.layers.3._codebook.embed_avg'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizer_state = {}\n",
    "for key in state.keys():\n",
    "    if 'quantizer' in key:\n",
    "        quantizer_state[key] = state[key]\n",
    "quantizer_state.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(quantizer_state, \"encodec_32khz_quantizer_nonHF.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncodecModel(\n",
       "  (encoder): EncodecEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncodecConv1d(\n",
       "        (conv): Conv1d(1, 64, kernel_size=(7,), stride=(1,))\n",
       "      )\n",
       "      (1): EncodecResnetBlock(\n",
       "        (block): ModuleList(\n",
       "          (0): ELU(alpha=1.0)\n",
       "          (1): EncodecConv1d(\n",
       "            (conv): Conv1d(64, 32, kernel_size=(3,), stride=(1,))\n",
       "          )\n",
       "          (2): ELU(alpha=1.0)\n",
       "          (3): EncodecConv1d(\n",
       "            (conv): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "      )\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): EncodecConv1d(\n",
       "        (conv): Conv1d(64, 128, kernel_size=(8,), stride=(4,))\n",
       "      )\n",
       "      (4): EncodecResnetBlock(\n",
       "        (block): ModuleList(\n",
       "          (0): ELU(alpha=1.0)\n",
       "          (1): EncodecConv1d(\n",
       "            (conv): Conv1d(128, 64, kernel_size=(3,), stride=(1,))\n",
       "          )\n",
       "          (2): ELU(alpha=1.0)\n",
       "          (3): EncodecConv1d(\n",
       "            (conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "      )\n",
       "      (5): ELU(alpha=1.0)\n",
       "      (6): EncodecConv1d(\n",
       "        (conv): Conv1d(128, 256, kernel_size=(8,), stride=(4,))\n",
       "      )\n",
       "      (7): EncodecResnetBlock(\n",
       "        (block): ModuleList(\n",
       "          (0): ELU(alpha=1.0)\n",
       "          (1): EncodecConv1d(\n",
       "            (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
       "          )\n",
       "          (2): ELU(alpha=1.0)\n",
       "          (3): EncodecConv1d(\n",
       "            (conv): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "      )\n",
       "      (8): ELU(alpha=1.0)\n",
       "      (9): EncodecConv1d(\n",
       "        (conv): Conv1d(256, 512, kernel_size=(10,), stride=(5,))\n",
       "      )\n",
       "      (10): EncodecResnetBlock(\n",
       "        (block): ModuleList(\n",
       "          (0): ELU(alpha=1.0)\n",
       "          (1): EncodecConv1d(\n",
       "            (conv): Conv1d(512, 256, kernel_size=(3,), stride=(1,))\n",
       "          )\n",
       "          (2): ELU(alpha=1.0)\n",
       "          (3): EncodecConv1d(\n",
       "            (conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "      )\n",
       "      (11): ELU(alpha=1.0)\n",
       "      (12): EncodecConv1d(\n",
       "        (conv): Conv1d(512, 1024, kernel_size=(16,), stride=(8,))\n",
       "      )\n",
       "      (13): EncodecLSTM(\n",
       "        (lstm): LSTM(1024, 1024, num_layers=2)\n",
       "      )\n",
       "      (14): ELU(alpha=1.0)\n",
       "      (15): EncodecConv1d(\n",
       "        (conv): Conv1d(1024, 128, kernel_size=(7,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): EncodecDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncodecConv1d(\n",
       "        (conv): Conv1d(128, 1024, kernel_size=(7,), stride=(1,))\n",
       "      )\n",
       "      (1): EncodecLSTM(\n",
       "        (lstm): LSTM(1024, 1024, num_layers=2)\n",
       "      )\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): EncodecConvTranspose1d(\n",
       "        (conv): ConvTranspose1d(1024, 512, kernel_size=(16,), stride=(8,))\n",
       "      )\n",
       "      (4): EncodecResnetBlock(\n",
       "        (block): ModuleList(\n",
       "          (0): ELU(alpha=1.0)\n",
       "          (1): EncodecConv1d(\n",
       "            (conv): Conv1d(512, 256, kernel_size=(3,), stride=(1,))\n",
       "          )\n",
       "          (2): ELU(alpha=1.0)\n",
       "          (3): EncodecConv1d(\n",
       "            (conv): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "      )\n",
       "      (5): ELU(alpha=1.0)\n",
       "      (6): EncodecConvTranspose1d(\n",
       "        (conv): ConvTranspose1d(512, 256, kernel_size=(10,), stride=(5,))\n",
       "      )\n",
       "      (7): EncodecResnetBlock(\n",
       "        (block): ModuleList(\n",
       "          (0): ELU(alpha=1.0)\n",
       "          (1): EncodecConv1d(\n",
       "            (conv): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
       "          )\n",
       "          (2): ELU(alpha=1.0)\n",
       "          (3): EncodecConv1d(\n",
       "            (conv): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "      )\n",
       "      (8): ELU(alpha=1.0)\n",
       "      (9): EncodecConvTranspose1d(\n",
       "        (conv): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(4,))\n",
       "      )\n",
       "      (10): EncodecResnetBlock(\n",
       "        (block): ModuleList(\n",
       "          (0): ELU(alpha=1.0)\n",
       "          (1): EncodecConv1d(\n",
       "            (conv): Conv1d(128, 64, kernel_size=(3,), stride=(1,))\n",
       "          )\n",
       "          (2): ELU(alpha=1.0)\n",
       "          (3): EncodecConv1d(\n",
       "            (conv): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "      )\n",
       "      (11): ELU(alpha=1.0)\n",
       "      (12): EncodecConvTranspose1d(\n",
       "        (conv): ConvTranspose1d(128, 64, kernel_size=(8,), stride=(4,))\n",
       "      )\n",
       "      (13): EncodecResnetBlock(\n",
       "        (block): ModuleList(\n",
       "          (0): ELU(alpha=1.0)\n",
       "          (1): EncodecConv1d(\n",
       "            (conv): Conv1d(64, 32, kernel_size=(3,), stride=(1,))\n",
       "          )\n",
       "          (2): ELU(alpha=1.0)\n",
       "          (3): EncodecConv1d(\n",
       "            (conv): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "        (shortcut): Identity()\n",
       "      )\n",
       "      (14): ELU(alpha=1.0)\n",
       "      (15): EncodecConv1d(\n",
       "        (conv): Conv1d(64, 1, kernel_size=(7,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (quantizer): EncodecResidualVectorQuantizer(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x EncodecVectorQuantization(\n",
       "        (codebook): EncodecEuclideanCodebook()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_name_or_path': 'ArthurZ/encodec_48khz', 'architectures': ['EncodecModel'], 'audio_channels': 2, 'chunk_length_s': 1.0, 'codebook_dim': 128, 'codebook_size': 1024, 'compress': 2, 'dilation_growth_rate': 2, 'hidden_size': 128, 'kernel_size': 7, 'last_kernel_size': 7, 'model_type': 'encodec', 'norm_type': 'time_group_norm', 'normalize': True, 'num_filters': 32, 'num_lstm_layers': 2, 'num_residual_layers': 1, 'overlap': 0.01, 'pad_mode': 'reflect', 'residual_kernel_size': 3, 'sampling_rate': 48000, 'target_bandwidths': [3.0, 6.0, 12.0, 24.0], 'torch_dtype': 'float32', 'transformers_version': '4.31.0.dev0', 'trim_right_ratio': 1.0, 'upsampling_ratios': [8, 5, 4, 2], 'use_causal_conv': False}\n"
     ]
    }
   ],
   "source": [
    "with open('encodec_32khz_config.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.encodec.configuration_encodec import EncodecConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('layers.0.codebook.inited', tensor([1.])),\n",
       "             ('layers.0.codebook.cluster_size',\n",
       "              tensor([0.3551, 0.1121, 0.0704,  ..., 0.4311, 0.0968, 0.0752])),\n",
       "             ('layers.0.codebook.embed',\n",
       "              tensor([[ 2.3788,  3.0058, -2.3097,  ...,  0.1857,  3.3994,  2.0836],\n",
       "                      [ 2.2991, -4.7996,  4.0720,  ...,  4.2219, -1.9379,  4.2589],\n",
       "                      [-2.7116, -3.0016,  4.5625,  ...,  0.1807,  0.8780, -0.0471],\n",
       "                      ...,\n",
       "                      [-1.7840, -1.6820,  3.6292,  ...,  0.7658, -0.3749, -0.0599],\n",
       "                      [ 1.3861, -3.3283,  0.4663,  ...,  0.4332,  1.1878, -0.8231],\n",
       "                      [ 1.1625, -0.7506,  4.0101,  ..., -3.3142, -0.0616, -2.2769]])),\n",
       "             ('layers.0.codebook.embed_avg',\n",
       "              tensor([[ 0.8448,  1.0666, -0.8199,  ...,  0.0662,  1.2071,  0.7399],\n",
       "                      [ 0.2579, -0.5378,  0.4559,  ...,  0.4734, -0.2173,  0.4778],\n",
       "                      [-0.1907, -0.2104,  0.3204,  ...,  0.0109,  0.0617, -0.0034],\n",
       "                      ...,\n",
       "                      [-0.7676, -0.7247,  1.5632,  ...,  0.3301, -0.1613, -0.0249],\n",
       "                      [ 0.1347, -0.3228,  0.0460,  ...,  0.0422,  0.1153, -0.0800],\n",
       "                      [ 0.0872, -0.0559,  0.3010,  ..., -0.2492, -0.0042, -0.1710]])),\n",
       "             ('layers.1.codebook.inited', tensor([1.])),\n",
       "             ('layers.1.codebook.cluster_size',\n",
       "              tensor([1.8139e-01, 5.1918e-05, 1.9425e-01,  ..., 2.7912e-01, 1.3474e-01,\n",
       "                      5.1405e-01])),\n",
       "             ('layers.1.codebook.embed',\n",
       "              tensor([[-1.2959, -1.7979,  1.9733,  ...,  0.1750,  0.3903,  0.2509],\n",
       "                      [ 0.2438,  1.8116, -0.6415,  ...,  5.9521, 11.2294, -0.5219],\n",
       "                      [ 1.4916,  3.1976,  1.0572,  ..., -0.3307, -1.7978, -0.5900],\n",
       "                      ...,\n",
       "                      [-0.7312,  0.0938,  3.1010,  ..., -0.1355,  0.1002, -0.2710],\n",
       "                      [-3.7387, -1.7753,  5.0019,  ...,  0.6924,  0.2341, -0.1514],\n",
       "                      [-1.0339, -1.7401,  0.0774,  ..., -0.0208,  0.8403,  0.6801]])),\n",
       "             ('layers.1.codebook.embed_avg',\n",
       "              tensor([[-2.3507e-01, -3.2667e-01,  3.5995e-01,  ...,  3.1374e-02,\n",
       "                        7.1493e-02,  4.3304e-02],\n",
       "                      [ 1.7625e-05,  1.3130e-04, -4.3219e-05,  ...,  4.3312e-04,\n",
       "                        8.2134e-04, -3.8900e-05],\n",
       "                      [ 2.9010e-01,  6.2120e-01,  2.0622e-01,  ..., -6.4183e-02,\n",
       "                       -3.4897e-01, -1.1478e-01],\n",
       "                      ...,\n",
       "                      [-2.0280e-01,  2.4715e-02,  8.6374e-01,  ..., -3.8445e-02,\n",
       "                        2.5974e-02, -7.6036e-02],\n",
       "                      [-5.0202e-01, -2.3995e-01,  6.7249e-01,  ...,  9.3630e-02,\n",
       "                        3.1540e-02, -2.0113e-02],\n",
       "                      [-5.3116e-01, -8.9459e-01,  3.9653e-02,  ..., -1.1068e-02,\n",
       "                        4.3212e-01,  3.4956e-01]])),\n",
       "             ('layers.2.codebook.inited', tensor([1.])),\n",
       "             ('layers.2.codebook.cluster_size',\n",
       "              tensor([2.9440e-01, 2.1829e-01, 5.8332e-01,  ..., 6.5028e-01, 2.1424e-01,\n",
       "                      4.7673e-04])),\n",
       "             ('layers.2.codebook.embed',\n",
       "              tensor([[ 0.3937,  0.2946, -1.1971,  ..., -0.7541, -0.0129, -0.8160],\n",
       "                      [-0.9581,  2.2230, -1.5819,  ...,  1.1791, -1.3381,  2.4693],\n",
       "                      [-0.2013,  1.0451, -0.8451,  ..., -1.1752,  0.4214, -0.3496],\n",
       "                      ...,\n",
       "                      [ 1.4743,  0.8390, -0.1006,  ...,  0.2756, -0.1740, -0.7177],\n",
       "                      [-0.7552, -0.3154, -1.5120,  ...,  0.2104,  2.8311,  0.9999],\n",
       "                      [ 7.0099, -2.7988, -4.9101,  ...,  2.2907, -0.0668, -2.5050]])),\n",
       "             ('layers.2.codebook.embed_avg',\n",
       "              tensor([[ 1.1594e-01,  8.6624e-02, -3.5248e-01,  ..., -2.2191e-01,\n",
       "                       -3.8038e-03, -2.4031e-01],\n",
       "                      [-2.0802e-01,  4.8572e-01, -3.4560e-01,  ...,  2.5676e-01,\n",
       "                       -2.9210e-01,  5.3930e-01],\n",
       "                      [-1.1752e-01,  6.1011e-01, -4.9317e-01,  ..., -6.8511e-01,\n",
       "                        2.4584e-01, -2.0386e-01],\n",
       "                      ...,\n",
       "                      [ 9.5803e-01,  5.4514e-01, -6.6092e-02,  ...,  1.7987e-01,\n",
       "                       -1.1341e-01, -4.6700e-01],\n",
       "                      [-1.6150e-01, -6.7087e-02, -3.2322e-01,  ...,  4.4828e-02,\n",
       "                        6.0629e-01,  2.1361e-01],\n",
       "                      [ 3.3898e-03, -8.4532e-04, -2.8332e-03,  ...,  1.4647e-03,\n",
       "                        1.4845e-04, -1.5977e-03]])),\n",
       "             ('layers.3.codebook.inited', tensor([1.])),\n",
       "             ('layers.3.codebook.cluster_size',\n",
       "              tensor([0.1896, 0.3154, 0.1001,  ..., 0.2096, 0.2665, 0.1041])),\n",
       "             ('layers.3.codebook.embed',\n",
       "              tensor([[ 2.5334,  0.8874, -0.5269,  ...,  1.1040, -0.4501,  0.3985],\n",
       "                      [ 0.1265,  0.1595,  0.7335,  ..., -0.7697,  0.2730,  0.0208],\n",
       "                      [ 0.3407,  3.3659,  1.5186,  ..., -2.0119, -1.3127,  1.3107],\n",
       "                      ...,\n",
       "                      [-0.0166, -1.8384,  0.4686,  ...,  0.0184,  0.8704, -1.5224],\n",
       "                      [-0.3265, -0.5965,  2.1886,  ...,  0.9976, -0.3960, -0.5923],\n",
       "                      [-1.1364,  0.3270, -0.8073,  ..., -1.7392, -1.3893, -0.2230]])),\n",
       "             ('layers.3.codebook.embed_avg',\n",
       "              tensor([[ 0.4802,  0.1682, -0.0999,  ...,  0.2092, -0.0854,  0.0753],\n",
       "                      [ 0.0399,  0.0503,  0.2309,  ..., -0.2429,  0.0857,  0.0063],\n",
       "                      [ 0.0346,  0.3359,  0.1518,  ..., -0.2013, -0.1317,  0.1307],\n",
       "                      ...,\n",
       "                      [-0.0031, -0.3852,  0.0981,  ...,  0.0030,  0.1822, -0.3192],\n",
       "                      [-0.0874, -0.1591,  0.5829,  ...,  0.2657, -0.1054, -0.1579],\n",
       "                      [-0.1184,  0.0333, -0.0839,  ..., -0.1819, -0.1445, -0.0236]]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.quantizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.encodec.modeling_encodec import EncodecResidualVectorQuantizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantizer.load_state_dict(model.model.quantizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.frame_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.quantizer.state_dict(), 'encodec_32khz_quantizer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EncodecConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mEncodecConfig\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebook/encodec_32khz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EncodecConfig' is not defined"
     ]
    }
   ],
   "source": [
    "config = EncodecConfig.from_pretrained('facebook/encodec_32khz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /home/jongmin/.cache/huggingface/hub/models--facebook--encodec_32khz/snapshots/d0c45384f6c44db055f78200cfdcb9c1c8706727/config.json\n",
      "Model config EncodecConfig {\n",
      "  \"architectures\": [\n",
      "    \"EncodecModel\"\n",
      "  ],\n",
      "  \"audio_channels\": 1,\n",
      "  \"chunk_length_s\": null,\n",
      "  \"codebook_dim\": 128,\n",
      "  \"codebook_size\": 2048,\n",
      "  \"compress\": 2,\n",
      "  \"dilation_growth_rate\": 2,\n",
      "  \"hidden_size\": 128,\n",
      "  \"kernel_size\": 7,\n",
      "  \"last_kernel_size\": 7,\n",
      "  \"model_type\": \"encodec\",\n",
      "  \"norm_type\": \"weight_norm\",\n",
      "  \"normalize\": false,\n",
      "  \"num_filters\": 64,\n",
      "  \"num_lstm_layers\": 2,\n",
      "  \"num_residual_layers\": 1,\n",
      "  \"overlap\": null,\n",
      "  \"pad_mode\": \"reflect\",\n",
      "  \"residual_kernel_size\": 3,\n",
      "  \"sampling_rate\": 32000,\n",
      "  \"target_bandwidths\": [\n",
      "    2.2\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.36.2\",\n",
      "  \"trim_right_ratio\": 1.0,\n",
      "  \"upsampling_ratios\": [\n",
      "    8,\n",
      "    5,\n",
      "    4,\n",
      "    4\n",
      "  ],\n",
      "  \"use_causal_conv\": false,\n",
      "  \"use_conv_shortcut\": false\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "quantizer = EncodecResidualVectorQuantizer(config = EncodecConfig.from_pretrained('facebook/encodec_32khz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemCodecMidiDecoder(nn.Module):\n",
    "  def __init__(self, in_channels=128, hidden_size=256, out_channels=88, kernel_size=3, stride=1, padding=1):\n",
    "      super().__init__()\n",
    "      self.out_channels = out_channels\n",
    "      # self.emb = SummationEmbedder(vocab_size=[2048, 2048, 2048, 2048], input_keys = 4, dim=in_channels)\n",
    "      self.layers = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=in_channels, out_channels=hidden_size, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(in_channels=hidden_size, out_channels=hidden_size, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Conv1d(in_channels=hidden_size, out_channels=hidden_size, kernel_size=kernel_size, stride=1, padding=1),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(0.5),\n",
    "        )\n",
    "      self.rnn = nn.GRU(input_size=hidden_size, hidden_size=hidden_size//2, num_layers=2, batch_first=True, bidirectional=True, dropout=0.2)\n",
    "      self.proj = nn.Linear(hidden_size, out_channels*2)\n",
    "      self.act = nn.Sigmoid()\n",
    "  \n",
    "  def forward(self, x):\n",
    "      # x = self.emb(x.permute(0,2,1))\n",
    "      x = self.layers(x)\n",
    "      x = self.rnn(x.permute(0,2,1))[0]\n",
    "      x = self.proj(x)\n",
    "      x = self.act(x.permute(0,2,1))\n",
    "      x = torch.stack([x[:,:88,:],x[:,88:,:]], dim=1)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemCodecOnlyMidi(nn.Module):\n",
    "  def __init__(self, in_channels=128, hidden_size=256, out_channels=88, kernel_size=3, stride=1, padding=1):\n",
    "      super().__init__()\n",
    "      self.frame_rate = 50\n",
    "      self.out_channels = out_channels\n",
    "      self.quantizer = EncodecResidualVectorQuantizer(config = EncodecConfig.from_pretrained('facebook/encodec_32khz'))\n",
    "      self.quantizer.load_state_dict(torch.load('/home/jongmin/userdata/audiocraft/encodec_32khz_quantizer.pt'))\n",
    "      self.decoder = SemCodecMidiDecoder(in_channels=in_channels, hidden_size=hidden_size, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "  def forward(self, x):\n",
    "      x = self.quantizer.decode(x)\n",
    "      x = self.decoder(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.encodec.modeling_encodec import EncodecResidualVectorQuantizer\n",
    "from transformers.models.encodec.configuration_encodec import EncodecConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SemCodecOnlyMidi(\n",
       "  (quantizer): EncodecResidualVectorQuantizer(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x EncodecVectorQuantization(\n",
       "        (codebook): EncodecEuclideanCodebook()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): SemCodecMidiDecoder(\n",
       "    (layers): Sequential(\n",
       "      (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ELU(alpha=1.0)\n",
       "      (3): Dropout(p=0.5, inplace=False)\n",
       "      (4): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (6): ELU(alpha=1.0)\n",
       "      (7): Dropout(p=0.5, inplace=False)\n",
       "      (8): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (9): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (10): ELU(alpha=1.0)\n",
       "      (11): Dropout(p=0.5, inplace=False)\n",
       "    )\n",
       "    (rnn): GRU(256, 128, num_layers=2, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "    (proj): Linear(in_features=256, out_features=176, bias=True)\n",
       "    (act): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semcodecmidi = SemCodecOnlyMidi()\n",
    "semcodecmidi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.load(\"/home/jongmin/userdata/MAESTRO/maestro-v3.0.0/2004/MIDI-Unprocessed_SMF_02_R1_2004_01-05_ORIG_MID--AUDIO_02_R1_2004_05_Track05_wav_encodec.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 1500])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = torch.stack([tokens[0].squeeze(0),tokens[30].squeeze(0)])\n",
    "token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = semcodecmidi(token.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 88, 1500])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd    \n",
    "jsonObj = pd.read_json(path_or_buf='/home/jongmin/userdata/SemCodec/egs/midiaudio_test/data.jsonl', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in jsonObj[\"duration\"]:\n",
    "    if i < 30:\n",
    "        print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiocraft-ssbSDm-j",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
